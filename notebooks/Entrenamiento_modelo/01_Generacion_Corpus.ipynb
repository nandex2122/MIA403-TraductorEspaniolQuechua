{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4a8d4c-79e6-4aba-96f5-78cf62481b44",
   "metadata": {},
   "source": [
    "## 1) somosnlp-hackathon-2022 \n",
    "## https://huggingface.co/datasets/somosnlp-hackathon-2022/spanish-to-quechua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42c7ea45-ad56-4713-970e-fe04d21452b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ¡Listo! Los archivos fueron guardados correctamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 1. Ruta de guardado\n",
    "ruta_base = \"D:/Jose/UNI/Maestria IA/Cursos/03_Tercer_ciclo/03_Proyecto_Tesis/Proyecto/Diccionarios/huggingface/somosnlp-hackathon-2022/Dataset\"\n",
    "os.makedirs(ruta_base, exist_ok=True)\n",
    "\n",
    "# 2. Cargar dataset\n",
    "dataset = load_dataset(\"somosnlp-hackathon-2022/spanish-to-quechua\")\n",
    "\n",
    "# 3. Guardar cada división con el formato solicitado\n",
    "def guardar_con_codigos(data_split, nombre_archivo):\n",
    "    with open(nombre_archivo, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, ejemplo in enumerate(data_split, 1):\n",
    "            codigo = f\"{i:06d}\"\n",
    "            esp = ejemplo[\"es\"].strip().replace(\"\\n\", \" \")\n",
    "            que = ejemplo[\"qu\"].strip().replace(\"\\n\", \" \")\n",
    "            f.write(f\"{codigo} {esp} {codigo} {que}\\n\")\n",
    "\n",
    "# 4. Guardar los splits\n",
    "guardar_con_codigos(dataset[\"train\"], os.path.join(ruta_base, \"train.txt\"))\n",
    "guardar_con_codigos(dataset[\"validation\"], os.path.join(ruta_base, \"validation.txt\"))\n",
    "guardar_con_codigos(dataset[\"test\"], os.path.join(ruta_base, \"test.txt\"))\n",
    "\n",
    "print(\" ¡Listo! Los archivos fueron guardados correctamente.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d74f34-2672-461d-bc8d-36dcc0abdebe",
   "metadata": {},
   "source": [
    "## Juntando los archivos en uno solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f68f6658-4b13-46cb-90e3-e0a0337df9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Archivo corpus_total.txt generado correctamente con códigos únicos.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "ruta_base = \"D:/Jose/UNI/Maestria IA/Cursos/03_Tercer_ciclo/03_Proyecto_Tesis/Proyecto/Diccionarios/huggingface/somosnlp-hackathon-2022/Dataset\"\n",
    "archivos_entrada = [\"train.txt\", \"validation.txt\", \"test.txt\"]\n",
    "archivo_salida = \"corpus_total.txt\"\n",
    "\n",
    "contador = 1\n",
    "\n",
    "# Expresión regular para capturar:\n",
    "# código + texto español + código + texto quechua\n",
    "patron = re.compile(r\"(\\d{6}) (.+?) (\\d{6}) (.+)\")\n",
    "\n",
    "with open(os.path.join(ruta_base, archivo_salida), \"w\", encoding=\"utf-8\") as fout:\n",
    "    for archivo in archivos_entrada:\n",
    "        path_archivo = os.path.join(ruta_base, archivo)\n",
    "        with open(path_archivo, \"r\", encoding=\"utf-8\") as fin:\n",
    "            for linea in fin:\n",
    "                linea = linea.strip()\n",
    "                m = patron.match(linea)\n",
    "                if m:\n",
    "                    # Extraemos solo los textos, ignorando los códigos originales\n",
    "                    esp = m.group(2)\n",
    "                    que = m.group(4)\n",
    "                    codigo = f\"{contador:06d}\"\n",
    "                    fout.write(f\"{codigo} {esp} {codigo} {que}\\n\")\n",
    "                    contador += 1\n",
    "                else:\n",
    "                    print(f\" Línea ignorada (no cumple formato esperado): {linea}\")\n",
    "\n",
    "print(\" Archivo corpus_total.txt generado correctamente con códigos únicos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296fd4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash SHA-256 del archivo 'D:/Jose/UNI/Maestria IA/Cursos/03_Tercer_ciclo/03_Proyecto_Tesis/Proyecto/Diccionarios/huggingface/somosnlp-hackathon-2022/Dataset/01_corpus_total.txt':\n",
      "3b7e7fed69aeeabb5eb3802c4dd74e6166ddb0c5341f9ee7161068fbc821bc77\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "archivo_salida = \"D:/Jose/UNI/Maestria IA/Cursos/03_Tercer_ciclo/03_Proyecto_Tesis/Proyecto/Diccionarios/huggingface/somosnlp-hackathon-2022/Dataset/01_corpus_total.txt\"\n",
    "archivo_salida = \"data/corpus_total_combinado.txt\"\n",
    "\n",
    "\n",
    "def generar_hash_sha256(ruta_archivo):\n",
    "    sha256 = hashlib.sha256()\n",
    "    with open(ruta_archivo, \"rb\") as f:\n",
    "        for bloque in iter(lambda: f.read(4096), b\"\"):\n",
    "            sha256.update(bloque)\n",
    "    return sha256.hexdigest()\n",
    "\n",
    "# Ejemplo de uso\n",
    "archivo = archivo_salida\n",
    "hash_resultado = generar_hash_sha256(archivo)\n",
    "print(f\"Hash SHA-256 del archivo '{archivo}':\\n{hash_resultado}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1fdc85-c2e5-4d61-a758-cab65a66f8f7",
   "metadata": {},
   "source": [
    "## 2)  Pollitoconpapas\n",
    "## https://huggingface.co/datasets/pollitoconpapass/cuzco-quechua-translation-spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f36f7017-1637-4fd7-8729-0bad988539b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits disponibles: dict_keys(['train', 'validate', 'test'])\n",
      " Archivos guardados correctamente.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "ruta_base = \"D:/Jose/UNI/Maestria IA/Cursos/03_Tercer_ciclo/03_Proyecto_Tesis/Proyecto/Diccionarios/huggingface/pollitoconpapass/Dataset\"\n",
    "os.makedirs(ruta_base, exist_ok=True)\n",
    "\n",
    "dataset = load_dataset(\"pollitoconpapass/cuzco-quechua-translation-spanish\")\n",
    "\n",
    "print(\"Splits disponibles:\", dataset.keys())\n",
    "\n",
    "def guardar_con_codigos(data_split, nombre_archivo, start_index=1):\n",
    "    with open(nombre_archivo, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, ejemplo in enumerate(data_split, start_index):\n",
    "            codigo = f\"{i:06d}\"\n",
    "            esp = ejemplo[\"spa\"].strip().replace(\"\\n\", \" \")\n",
    "            que = ejemplo[\"quz\"].strip().replace(\"\\n\", \" \")\n",
    "            f.write(f\"{codigo} {esp} {codigo} {que}\\n\")\n",
    "    return i + 1\n",
    "\n",
    "indice = 1\n",
    "indice = guardar_con_codigos(dataset[\"train\"], os.path.join(ruta_base, \"train.txt\"), start_index=indice)\n",
    "indice = guardar_con_codigos(dataset[\"validate\"], os.path.join(ruta_base, \"validate.txt\"), start_index=indice)\n",
    "indice = guardar_con_codigos(dataset[\"test\"], os.path.join(ruta_base, \"test.txt\"), start_index=indice)\n",
    "\n",
    "print(\" Archivos guardados correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f07d70-e0e6-413c-bdd2-5cb67d1e469a",
   "metadata": {},
   "source": [
    "## Juntando los archivos en uno solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce3f15d3-2790-4cf2-80b3-657a83b5eaba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Línea ignorada (formato inesperado): 000028 ella se levantó de prisa, pero ya no lo alcanzó porque estaba amaneciendo. 000028\n",
      " Línea ignorada (formato inesperado): 000220 K’alla 000220\n",
      " Línea ignorada (formato inesperado): 106460 ella se levantó de prisa, pero ya no lo alcanzó porque estaba amaneciendo. 106460\n",
      " Línea ignorada (formato inesperado): 106652 K’alla 106652\n",
      " Archivo combinado corpus_total.txt creado correctamente.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ruta_base = \"D:/Jose/UNI/Maestria IA/Cursos/03_Tercer_ciclo/03_Proyecto_Tesis/Proyecto/Diccionarios/huggingface/pollitoconpapass/Dataset\"\n",
    "archivos_entrada = [\"train.txt\", \"validate.txt\", \"test.txt\"]\n",
    "archivo_salida = \"corpus_total.txt\"\n",
    "contador = 1\n",
    "patron = re.compile(r\"(\\d{6}) (.+?) (\\d{6}) (.+)\")\n",
    "\n",
    "with open(os.path.join(ruta_base, archivo_salida), \"w\", encoding=\"utf-8\") as fout:\n",
    "    for archivo in archivos_entrada:\n",
    "        path_archivo = os.path.join(ruta_base, archivo)\n",
    "        with open(path_archivo, \"r\", encoding=\"utf-8\") as fin:\n",
    "            for linea in fin:\n",
    "                linea = linea.strip()\n",
    "                m = patron.match(linea)\n",
    "                if m:\n",
    "                    esp = m.group(2)\n",
    "                    que = m.group(4)\n",
    "                    codigo = f\"{contador:06d}\"\n",
    "                    fout.write(f\"{codigo} {esp} {codigo} {que}\\n\")\n",
    "                    contador += 1\n",
    "                else:\n",
    "                    print(f\" Línea ignorada (formato inesperado): {linea}\")\n",
    "\n",
    "print(f\" Archivo combinado {archivo_salida} creado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db6c596-8390-4a57-b0c2-8c1e15707782",
   "metadata": {},
   "source": [
    "## Juntando los 2 corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f4f8a72-4ed8-451a-a2b1-6e24ac0c720c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Corpus combinado creado en:\n",
      "D:/Jose/UNI/Maestria IA/Cursos/03_Tercer_ciclo/03_Proyecto_Tesis/Proyecto/Diccionarios/huggingface\\corpus_total_combinado.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Ruta donde están los corpus generados\n",
    "ruta_base = \"D:/Jose/UNI/Maestria IA/Cursos/03_Tercer_ciclo/03_Proyecto_Tesis/Proyecto/Diccionarios/huggingface\"\n",
    "\n",
    "# Archivos a combinar (ajusta nombres y rutas)\n",
    "archivos_entrada = [\n",
    "    os.path.join(ruta_base, \"somosnlp-hackathon-2022\", \"Dataset\", \"corpus_total.txt\"),  # ejemplo somosnlp\n",
    "    os.path.join(ruta_base, \"pollitoconpapass\",\"Dataset\", \"corpus_total.txt\")        # ejemplo pollito\n",
    "]\n",
    "\n",
    "archivo_salida = os.path.join(ruta_base, \"corpus_total_combinado.txt\")\n",
    "\n",
    "contador = 1\n",
    "patron = re.compile(r\"(\\d{6}) (.+?) (\\d{6}) (.+)\")\n",
    "\n",
    "with open(archivo_salida, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for archivo in archivos_entrada:\n",
    "        with open(archivo, \"r\", encoding=\"utf-8\") as fin:\n",
    "            for linea in fin:\n",
    "                linea = linea.strip()\n",
    "                m = patron.match(linea)\n",
    "                if m:\n",
    "                    esp = m.group(2)\n",
    "                    que = m.group(4)\n",
    "                    codigo = f\"{contador:06d}\"\n",
    "                    fout.write(f\"{codigo} {esp} {codigo} {que}\\n\")\n",
    "                    contador += 1\n",
    "                else:\n",
    "                    print(f\" Línea ignorada (formato inesperado): {linea}\")\n",
    "\n",
    "print(f\" Corpus combinado creado en:\\n{archivo_salida}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2299356a-af9a-4c0a-9f14-47981913ee9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NS_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
