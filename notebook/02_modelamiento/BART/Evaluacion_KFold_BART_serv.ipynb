{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293ecf54-f4f2-4899-b0a1-929f60497598",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aea4b2-22ad-493e-b87e-adac9b126c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers datasets scikit-learn evaluate sacrebleu rouge_score matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcfbb83-5dd1-4138-8033-6425bccb32b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sacrebleu rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f3adc3-92cc-4fdb-ada9-95c57b48ada1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from sklearn.model_selection import KFold\n",
    "from datasets import Dataset\n",
    "from evaluate import load\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Instalación de librerías (descomenta si es necesario)\n",
    "# !pip install transformers datasets scikit-learn evaluate sacrebleu rouge_score matplotlib seaborn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2fc872-72b2-42c7-9601-208d1ef82c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm  # Para barra de progreso\n",
    "\n",
    "def load_and_prepare_data(csv_path):\n",
    "    # Leer el CSV especificando las columnas correctas\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            csv_path,\n",
    "            usecols=['source', 'target'],  # Solo cargar las columnas necesarias\n",
    "            encoding='utf-8',\n",
    "            on_bad_lines='warn'  # Mostrar advertencias si hay líneas mal formateadas\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error al leer el CSV: {e}\")\n",
    "        return Dataset.from_list([])\n",
    "    \n",
    "    # Verificar datos faltantes\n",
    "    print(\"\\nResumen de datos faltantes:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Limpiar y preparar los datos\n",
    "    data_pairs = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Procesando filas\"):\n",
    "        if pd.notna(row['source']) and pd.notna(row['target']):\n",
    "            data_pairs.append({\n",
    "                \"spanish\": str(row['source']).strip(),  # Español (source)\n",
    "                \"quechua\": str(row['target']).strip()   # Quechua (target)\n",
    "            })\n",
    "    \n",
    "    print(f\"\\nTotal de pares válidos cargados: {len(data_pairs)}\")\n",
    "    \n",
    "    # Estadísticas básicas\n",
    "    if data_pairs:\n",
    "        avg_len_spanish = sum(len(pair['spanish']) for pair in data_pairs) / len(data_pairs)\n",
    "        avg_len_quechua = sum(len(pair['quechua']) for pair in data_pairs) / len(data_pairs)\n",
    "        print(f\"\\nLongitud promedio:\")\n",
    "        print(f\"- Español: {avg_len_spanish:.1f} caracteres\")\n",
    "        print(f\"- Quechua: {avg_len_quechua:.1f} caracteres\")\n",
    "    \n",
    "    return Dataset.from_list(data_pairs)\n",
    "\n",
    "# Ruta al archivo CSV\n",
    "csv_file_path = r\"C:\\DATA\\FERNANDOHC\\EDUCACION\\MAESTRIA\\UNI_MAI\\SEMESTRE_3\\MIA-204ProyectoDeInvestigacion1\\Proyecto_Traductor_Esp_Quechua\\datos\\corpus_trad.csv\"\n",
    "\n",
    "# Cargar datos\n",
    "raw_dataset = load_and_prepare_data(csv_file_path)\n",
    "\n",
    "# Verificación detallada\n",
    "if len(raw_dataset) > 0:\n",
    "    print(\"\\nEjemplos cargados (formato español -> quechua):\")\n",
    "    for i in range(min(3, len(raw_dataset))):\n",
    "        print(f\"\\nEjemplo {i+1}:\")\n",
    "        print(f\"Español: {raw_dataset[i]['spanish']}\")\n",
    "        print(f\"Quechua: {raw_dataset[i]['quechua']}\")\n",
    "        \n",
    "    # Verificación de distribución\n",
    "    sample = raw_dataset.shuffle().select(range(5))\n",
    "    print(\"\\nMuestra aleatoria:\")\n",
    "    for example in sample:\n",
    "        print(f\"\\nEspañol: {example['spanish']}\")\n",
    "        print(f\"Quechua: {example['quechua']}\")\n",
    "else:\n",
    "    print(\"\\nNo se cargaron datos válidos. Verifica:\")\n",
    "    print(\"1. Que las columnas se llamen 'source' y 'target'\")\n",
    "    print(\"2. Que el archivo contenga datos\")\n",
    "    print(\"3. Que no haya caracteres especiales corruptos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66978159-8294-4555-80b8-ad4d8c52f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_TYPE = \"BART\"\n",
    "NUM_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "metric_bleu = load(\"bleu\")\n",
    "metric_rouge = load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    references_bleu = [[label] for label in decoded_labels]\n",
    "\n",
    "    bleu_results = metric_bleu.compute(predictions=decoded_preds, references=references_bleu)\n",
    "    rouge_results = metric_rouge.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    return {\n",
    "        \"bleu\": bleu_results[\"bleu\"],\n",
    "        \"rouge-l\": rouge_results[\"rougeL\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeaeb29-9196-462c-a534-936196da0712",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers[torch] accelerate evaluate sacrebleu rouge_score\n",
    "!pip install --force-reinstall accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5b6069-bd82-4c0d-91ce-a542f9197cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "# --- Configuración ---\n",
    "MODEL_TYPE = \"BART\"\n",
    "NUM_FOLDS = 5\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Verificar si hay GPU disponible\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# --- Función de preprocesamiento ---\n",
    "def preprocess_function(examples, current_tokenizer):\n",
    "    inputs = current_tokenizer(\n",
    "        examples[\"quechua\"], \n",
    "        max_length=128, \n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    labels = current_tokenizer(\n",
    "        text_target=examples[\"spanish\"],\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "# --- K-Fold Cross Validation ---\n",
    "kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "bleu_scores_baseline = []\n",
    "rouge_l_scores_baseline = []\n",
    "\n",
    "bleu_scores_refined = []\n",
    "rouge_l_scores_refined = []\n",
    "\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(raw_dataset)):\n",
    "    print(f\"\\n--- Iniciando Fold {fold + 1}/{NUM_FOLDS} ---\")\n",
    "    val_dataset_fold = raw_dataset.select(val_index)\n",
    "    \n",
    "    # --- Evaluación del Modelo BART Baseline ---\n",
    "    print(f\"Evaluando Modelo BART Baseline (inicial) en Fold {fold + 1}...\")\n",
    "    try:\n",
    "        model_path_baseline = r\"C:\\DATA\\FERNANDOHC\\EDUCACION\\MAESTRIA\\UNI_MAI\\SEMESTRE_3\\MIA-204ProyectoDeInvestigacion1\\Proyecto_Traductor_Esp_Quechua\\modelos\\BART\\v1\"\n",
    "        \n",
    "        # Cargar modelo y tokenizer\n",
    "        tokenizer_baseline = AutoTokenizer.from_pretrained(model_path_baseline)\n",
    "        model_baseline = AutoModelForSeq2SeqLM.from_pretrained(model_path_baseline).to(device)\n",
    "        \n",
    "        # Preprocesar datos\n",
    "        tokenized_val_dataset_baseline = val_dataset_fold.map(\n",
    "            lambda examples: preprocess_function(examples, tokenizer_baseline),\n",
    "            batched=True,\n",
    "            remove_columns=[\"quechua\", \"spanish\"]\n",
    "        )\n",
    "\n",
    "        # Configuración del entrenador para evaluación\n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir=r\"./temp_eval_baseline\",\n",
    "            per_device_eval_batch_size=8,\n",
    "            predict_with_generate=True,\n",
    "            fp16=torch.cuda.is_available(),\n",
    "            report_to=\"none\"\n",
    "        )\n",
    "\n",
    "        trainer_baseline = Seq2SeqTrainer(\n",
    "            model=model_baseline,\n",
    "            args=training_args,\n",
    "            tokenizer=tokenizer_baseline,\n",
    "            compute_metrics=compute_metrics\n",
    "        )\n",
    "        \n",
    "        # Evaluación\n",
    "        eval_results_baseline = trainer_baseline.evaluate(tokenized_val_dataset_baseline)\n",
    "        \n",
    "        # Guardar resultados\n",
    "        bleu_score = eval_results_baseline.get(\"eval_bleu\", 0.0)\n",
    "        rouge_score = eval_results_baseline.get(\"eval_rouge-l\", 0.0)\n",
    "        \n",
    "        bleu_scores_baseline.append(bleu_score)\n",
    "        rouge_l_scores_baseline.append(rouge_score)\n",
    "        \n",
    "        print(f\"  BART Baseline - BLEU: {bleu_score:.4f}, ROUGE-L: {rouge_score:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"  Error evaluando BART Baseline en Fold {fold + 1}: {str(e)}\")\n",
    "        bleu_scores_baseline.append(0.0)\n",
    "        rouge_l_scores_baseline.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802ac8c-3250-4283-a04a-1ac1d2bfa174",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
